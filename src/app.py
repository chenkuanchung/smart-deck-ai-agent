# src/app.py
import streamlit as st
import os
import sys

# è·¯å¾‘ä¿®æ­£
current_file_path = os.path.abspath(__file__)
src_dir = os.path.dirname(current_file_path)
project_root = os.path.dirname(src_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.config import Config
from src.tools.rag import ingest_file, rag_tool, reset_vector_store, remove_file_from_db
from src.tools.search import search_tool
from src.graph import agent_workflow
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage

# --- [UX å„ªåŒ–] å·¥å…·åç¨±å°ç…§è¡¨ ---
TOOL_DISPLAY_NAMES = {
    "google_search": "ğŸŒ æ­£åœ¨æœå°‹ç¶²è·¯... (Web Research)",
    "read_knowledge_base": "ğŸ“š æ­£åœ¨åˆ†æå…§éƒ¨æ–‡ä»¶ (Document Analysis)"
}

# --- System Prompt (æœ€å¼·åˆé«”ç‰ˆï¼šæ·±åº¦æœå°‹ + æ„åœ–å°å‘) ---
SYSTEM_PROMPT_TEMPLATE = """
ä½ ç¾åœ¨æ˜¯ Smart Deck åœ˜éšŠçš„ **ã€Œé¦–å¸­ç­–ç•¥åˆ†æå¸« (Lead Strategy Analyst)ã€**ã€‚
ä½ ä¸åƒ…åƒ…æ˜¯ä¸€å€‹æœå°‹å·¥å…·ï¼Œä½ æ˜¯ä½¿ç”¨è€…çš„**ã€Œç°¡å ±é¡§å•ã€**èˆ‡**ã€Œå‰æœŸç­–åŠƒã€**ã€‚

ä½ çš„çµ‚æ¥µä»»å‹™ï¼šå”åŠ©ä½¿ç”¨è€…é€éå°è©±ï¼Œå°‡æ¨¡ç³Šçš„æƒ³æ³•è½‰åŒ–ç‚º**ã€Œé«˜è³‡è¨Šå¯†åº¦ã€é‚è¼¯åš´å¯†ã€**çš„ç°¡å ±ç´ æï¼Œæœ€å¾Œäº¤æ£’çµ¦ Manager (è¦åŠƒ) èˆ‡ Writer (æ’ç‰ˆ) é€²è¡Œè£½ä½œã€‚

---

### ğŸŒŸ ç•¶å‰ç’°å¢ƒæ„ŸçŸ¥ (Context Awareness)
- **å·²ä¸Šå‚³æ–‡ä»¶**ï¼š{file_count} ä»½ ({file_names})
- **ä½ çš„ä¸‹æ¸¸å¤¥ä¼´**ï¼š
  1. **Manager**ï¼šè² è²¬å¯«å¤§ç¶±ã€‚å®ƒéå¸¸å–œæ­¡ã€Œå…·é«”æ•¸æ“šã€ã€ã€Œå¹´ä»½ã€ã€ã€Œé‡‘é¡ã€èˆ‡ã€Œæ˜ç¢ºçµè«–ã€ã€‚
  2. **Writer**ï¼šè² è²¬æ’ç‰ˆã€‚åƒ…æ”¯æ´PPTç‰ˆå‹ï¼š`title`, `section`, `content`, `two_column`ã€‚

---

### ğŸ§  ä½ çš„æ€è€ƒèˆ‡è¡Œå‹•å”è­° (Cognitive Protocol)

ç•¶æ”¶åˆ°ä½¿ç”¨è€…è¨Šæ¯æ™‚ï¼Œè«‹ä¾ç…§ä»¥ä¸‹æ­¥é©Ÿæ€è€ƒï¼Œ**ä¸è¦åƒæ©Ÿå™¨äººä¸€æ¨£ç›´æ¥åŸ·è¡Œ**ï¼š

#### Step 1: æ„åœ–åµæ¸¬ (Intent Detection)
åˆ¤æ–·ä½¿ç”¨è€…ç¾åœ¨æƒ³è¦ä»€éº¼ï¼Ÿ
- **A. æ¢ç´¢/ç™¼æ•£**ï¼šåªçµ¦ä¸€å€‹åè©ï¼ˆå¦‚ "AI"ï¼‰ã€‚ -> **è¡Œå‹•**ï¼šä½ éœ€è¦å¼•å°èˆ‡æ”¶æ–‚ã€‚
- **B. é©—è­‰/æŸ¥è©¢**ï¼šå•å…·é«”å•é¡Œï¼ˆå¦‚ "å°ç©é›» 2024 Q3 ç‡Ÿæ”¶"ï¼‰ã€‚ -> **è¡Œå‹•**ï¼šç²¾æº–èª¿ç ”ã€‚
- **C. æ¯”è¼ƒ/åˆ†æ**ï¼šå•å·®ç•°ï¼ˆå¦‚ "æ²¹è»Š vs é›»è»Š"ï¼‰ã€‚ -> **è¡Œå‹•**ï¼šå°‹æ‰¾å°æ¯”ç¶­åº¦ï¼ˆæˆæœ¬ã€ç’°ä¿ã€æ•ˆèƒ½ï¼‰ã€‚
- **D. é–’èŠ/æ‰“æ‹›å‘¼**ï¼š -> **è¡Œå‹•**ï¼šå±•ç¾å°ˆæ¥­ç†±æƒ…ï¼Œå¼•å°è‡³ç°¡å ±ä¸»é¡Œã€‚

#### Step 2: è³‡è¨Šæ¨¡ç³Šåº¦æª¢æŸ¥ (Ambiguity Check) **(é—œéµï¼)**
- **è‹¥æŒ‡ä»¤å¤ªæ¨¡ç³Š**ï¼ˆä¾‹å¦‚åªèªª "åšä¸€ä»½ç°¡å ±" æˆ– "å¸‚å ´åˆ†æ"ï¼‰ï¼š
  - ğŸ›‘ **STOPï¼ä¸è¦æœå°‹ï¼**
  - ğŸ—£ï¸ **Action**ï¼šè«‹åå•ä½¿ç”¨è€…ã€‚ã€Œæ‚¨æƒ³èšç„¦åœ¨å“ªå€‹ç‰¹å®šå¸‚å ´ï¼Ÿä¸»è¦å—çœ¾æ˜¯æŠ•è³‡äººé‚„æ˜¯æŠ€è¡“äººå“¡ï¼Ÿã€
  - *å±•ç¾ä½ çš„é¡§å•åƒ¹å€¼ï¼Œå¹«åŠ©ä½¿ç”¨è€…é‡æ¸…éœ€æ±‚ã€‚*

- **è‹¥æŒ‡ä»¤å¤ æ¸…æ™°**ï¼š
  - âœ… **GOï¼å•Ÿå‹•å·¥å…·ã€‚**

#### Step 3: å·¥å…·èª¿åº¦ç­–ç•¥ (Tool Strategy)
- **å„ªå…ˆç´š**ï¼šç¸½æ˜¯å…ˆå•è‡ªå·±ã€Œé€™è³‡æ–™æ˜¯å¦åœ¨å·²ä¸Šå‚³çš„æ–‡ä»¶ (`read_knowledge_base`) è£¡ï¼Ÿã€
  - è‹¥æœ‰ä¸Šå‚³æ–‡ä»¶ -> **å„ªå…ˆæŸ¥æ–‡ä»¶**ï¼Œä¸¦å¼•ç”¨æ–‡ä»¶å…§å®¹ã€‚
  - è‹¥æ–‡ä»¶ç„¡è³‡æ–™/è³‡æ–™éæ™‚ -> **ç«‹åˆ»åˆ‡æ›** `Google Search` æ‰¾å¤–éƒ¨æœ€æ–°è³‡è¨Šã€‚
- **æœå°‹ç­–ç•¥ (Search Tactics)**ï¼š
  - 1. **è­˜åˆ¥æœå°‹é—œéµå­—**ï¼š ä¸è¦ç”¨ä½¿ç”¨è€…çš„åŸè©±æœå°‹ã€‚è«‹å°‡å…¶è½‰åŒ–ç‚º**ã€Œé«˜åƒ¹å€¼é—œéµå­—ã€**ã€‚
  - 2. **å¤šè§’åº¦é—œéµå­— (Multi-Angle Keywords)**ï¼š
     - å¦‚æœä¸»é¡Œå¯èƒ½æœ‰ä¸åŒç¨±å‘¼ï¼Œ**è«‹ä¸€æ¬¡ç”¢ç”Ÿ 2~3 å€‹ä¸åŒçš„æœå°‹å·¥å…·å‘¼å« (Parallel Function Calling)**ã€‚
     - *ç¯„ä¾‹*ï¼šè‹¥ä½¿ç”¨è€…å• "NotebookLM ç°¡å ±åŠŸèƒ½"ï¼Œä½ æ‡‰è©²åŒæ™‚å‘¼å«ä¸‰æ¬¡æœå°‹ï¼š
       - Query 1: `"NotebookLM audio overview features"` (å®˜æ–¹å¯èƒ½ç”¨èª)
       - Query 2: `"Google NotebookLM slide deck"` (å¸¸è¦‹ç¨±å‘¼)
       - Query 3: `"Google NotebookLM latest updates"` (å»£æ³›è³‡è¨Š)
  3. **é‡å°æ€§**ï¼šè‹¥ç‚ºäº†æ¯”è¼ƒï¼Œæœå°‹ `"A vs B features"`, `"A vs B pricing"`ã€‚

#### Step 4: å›æ‡‰èˆ‡è¼¸å‡º (Response)
- **ä¸è¦åªä¸Ÿé€£çµ**ã€‚è«‹å°‡æœå°‹åˆ°çš„è³‡è¨Š**ã€Œæ¶ˆåŒ–ã€**éã€‚

---

### âš ï¸ çµ•å°ç¦å€ (Strict Rules)
1. **åš´ç¦å‘¼å«ç©ºåƒæ•¸**ï¼šå‘¼å«å·¥å…·æ™‚ï¼Œ`query` å¿…é ˆå¡«å…¥å…·é«”å…§å®¹ã€‚
2. **åš´ç¦çæ°**ï¼šRAG æ‰¾ä¸åˆ°å°±èªªæ‰¾ä¸åˆ°ï¼Œç„¶å¾Œä¸»å‹•å»ºè­°å» Google æœã€‚
3. **ä¿æŒå°è©±è¨˜æ†¶**ï¼šè‹¥ä½¿ç”¨è€…èªªã€ŒæŠŠå‰›å‰›æŸ¥åˆ°çš„ A å’Œ B æ•´åˆã€ï¼Œè«‹æ ¹æ“š Chat History åŸ·è¡Œï¼Œä¸è¦å• A å’Œ B æ˜¯ä»€éº¼ã€‚

ç¾åœ¨ï¼Œè«‹ä»¥ä¸€ä½å°ˆæ¥­ã€ä¸»å‹•ä¸”å…·å‚™æ´å¯ŸåŠ›çš„åˆ†æå¸«èº«åˆ†é–‹å§‹äº’å‹•ã€‚
"""

# Init
st.set_page_config(page_title="Smart Deck Agent", page_icon="ğŸ“Š", layout="wide")
try: Config.validate()
except Exception as e: st.error(f"ç’°å¢ƒè¨­å®šéŒ¯èª¤: {e}"); st.stop()

if "app_initialized" not in st.session_state:
    reset_vector_store()
    st.session_state.app_initialized = True

# LLM
tools = [rag_tool, search_tool]
tool_map = {"read_knowledge_base": rag_tool, "google_search": search_tool}
llm = ChatGoogleGenerativeAI(
    model=Config.MODEL_FAST, google_api_key=Config.GOOGLE_API_KEY, temperature=0.7
)
llm_with_tools = llm.bind_tools(tools)

# Session
if "messages" not in st.session_state: st.session_state.messages = []
if "db_files" not in st.session_state: st.session_state.db_files = set() 
if "file_uploader_key" not in st.session_state: st.session_state.file_uploader_key = 0

# Sidebar
with st.sidebar:
    st.header("ğŸ“‚ è³‡æ–™ä¾†æº")
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³ PDF/TXT", 
        type=["pdf", "txt"], 
        accept_multiple_files=True, 
        key=f"uploader_{st.session_state.file_uploader_key}"
    )
    
    # 1. å»ºç«‹ç•¶å‰æª”æ¡ˆæ¸…å–®
    if uploaded_files is None:
        uploaded_files = []
    current_filenames = {f.name for f in uploaded_files}

    # 2. è™•ç†æ–°å¢æª”æ¡ˆ (New Files)
    new_files = [f for f in uploaded_files if f.name not in st.session_state.db_files]
    for file in new_files:
        with st.spinner(f"è™•ç†ä¸­ï¼š{file.name}..."):
            temp_path = os.path.join(Config.UPLOAD_DIR, file.name)
            if not os.path.exists(Config.UPLOAD_DIR):
                os.makedirs(Config.UPLOAD_DIR)
                
            with open(temp_path, "wb") as f: f.write(file.getbuffer())
            
            res = ingest_file(temp_path)
            
            if "âœ…" in res:
                st.session_state.db_files.add(file.name)
                st.session_state.messages.append(HumanMessage(content=f"[ç³»çµ±] {res}"))
                # [é—œéµä¿®æ­£] åœ¨å´é‚Šæ¬„é¡¯ç¤ºç¶ è‰²æˆåŠŸè¨Šæ¯
                st.success(res) 
            else: 
                st.error(res)

    # 3. è™•ç†ç§»é™¤æª”æ¡ˆ (Removed Files)
    removed_files = st.session_state.db_files - current_filenames
    
    if removed_files:
        for filename in removed_files:
            res = remove_file_from_db(filename)
            st.session_state.db_files.remove(filename)
            st.session_state.messages.append(HumanMessage(content=f"[ç³»çµ±] {res}"))
            # åœ¨å´é‚Šæ¬„é¡¯ç¤ºåˆªé™¤è¨Šæ¯
            st.success(res) 

    st.divider()
    
    # Reset æŒ‰éˆ•
    if st.button("ğŸ—‘ï¸ Reset", type="secondary"):
        reset_vector_store()
        st.session_state.db_files = set()
        st.session_state.messages = []
        st.session_state.file_uploader_key += 1
        st.rerun()

    if st.button("âœ¨ ç”Ÿæˆ PPT", type="primary"):
        with st.status("ğŸ¤– AI åœ˜éšŠå·¥ä½œä¸­...", expanded=True) as status:
            chat_history = "\n".join([f"{type(m).__name__}: {m.content}" for m in st.session_state.messages])
            
            status.write("ğŸ§  Manager: æ­£åœ¨è¦åŠƒç°¡å ±æ¶æ§‹...")
            final_state = agent_workflow.invoke({"user_request": "è£½ä½œç°¡å ±", "chat_history": chat_history})
            
            status.write("âœï¸ Writer: æ­£åœ¨æ’ç‰ˆèˆ‡è£½ä½œæŠ•å½±ç‰‡...")
            if final_state.get("final_file_path"):
                with open(final_state["final_file_path"], "rb") as f:
                    st.download_button("ğŸ“¥ ä¸‹è¼‰ PPT", f, os.path.basename(final_state["final_file_path"]))
                status.update(label="âœ… å®Œæˆï¼", state="complete")
            else: status.error("ç”Ÿæˆå¤±æ•—ï¼Œè«‹æª¢æŸ¥ Logã€‚")

# Chat Interface
st.title("ğŸ’¬ Smart Deck Agent")

for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"): st.markdown(msg.content)
    elif isinstance(msg, AIMessage) and msg.content:
        with st.chat_message("assistant"): st.markdown(msg.content)

if prompt := st.chat_input("è¼¸å…¥è¨Šæ¯ (ä¾‹å¦‚ï¼šæƒ³äº†è§£çš„ä¸»é¡Œã€ä¸Šå‚³æ–‡ä»¶å¾Œåˆ†æ)..."):
    st.session_state.messages.append(HumanMessage(content=prompt))
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        status_box = st.empty()
        
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                # 1. æ³¨å…¥å‹•æ…‹ Prompt (å‘ŠçŸ¥æª”æ¡ˆç‹€æ…‹)
                file_count = len(st.session_state.db_files)
                file_names = ", ".join(st.session_state.db_files) if file_count > 0 else "ç„¡"
                
                dynamic_system_prompt = SYSTEM_PROMPT_TEMPLATE.format(
                    file_count=file_count,
                    file_names=file_names
                )
                
                messages_to_send = [SystemMessage(content=dynamic_system_prompt)] + st.session_state.messages
                
                # 2. ç¬¬ä¸€æ¬¡å‘¼å« LLM
                response = llm_with_tools.invoke(messages_to_send)
                st.session_state.messages.append(response)

                # 3. å·¥å…·è¿´åœˆ (è’é›†è³‡è¨Š)
                while response.tool_calls:
                    for tool_call in response.tool_calls:
                        name = tool_call["name"]
                        args = tool_call["args"]
                        query_val = args.get("query", "")
                        
                        # [é˜²å‘†] è‹¥ LLM çµ¦ç©ºåƒæ•¸ï¼Œç›´æ¥ç”¨ä½¿ç”¨è€…çš„ Prompt (å³ä¸»é¡Œ)
                        # if not query_val:
                        #     query_val = prompt
                        #     tool_call["args"]["query"] = prompt 
                        
                        # [UI] é¡¯ç¤ºè¦ªåˆ‡åç¨± + æŸ¥è©¢å…§å®¹
                        display_name = TOOL_DISPLAY_NAMES.get(name, f"ğŸ”§ {name}")
                        status_box.info(f"{display_name}ï¼š{query_val}")
                        
                        # åŸ·è¡Œå·¥å…·
                        tool = tool_map.get(name)
                        output = tool.invoke(query_val) if tool else "Error: Tool not found"
                        
                        st.session_state.messages.append(
                            ToolMessage(content=str(output), tool_call_id=tool_call["id"], name=name)
                        )
                    
                    # å†æ¬¡å‘¼å« LLM (å¸¶è‘—æœå°‹çµæœ)
                    messages_to_send = [SystemMessage(content=dynamic_system_prompt)] + st.session_state.messages
                    response = llm_with_tools.invoke(messages_to_send)
                    st.session_state.messages.append(response)
                
                status_box.empty()
                st.markdown(response.content)

            except Exception as e:

                st.error(f"Error: {e}")
