# src/app.py
import streamlit as st
import os
import sys

# --- è·¯å¾‘ä¿®æ­£ ---
current_file_path = os.path.abspath(__file__)
src_dir = os.path.dirname(current_file_path)
project_root = os.path.dirname(src_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Import
from src.config import Config
from src.tools.rag import ingest_file, rag_tool
from src.tools.search import search_tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage

# --- NotebookLM é¢¨æ ¼ System Prompt ---
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹æ–‡ä»¶åˆ†æèˆ‡ç°¡å ±åŠ©æ‰‹ (Smart Deck Agent)ã€‚ä½ çš„æ ¸å¿ƒä»»å‹™æ˜¯å”åŠ©ä½¿ç”¨è€…ç†è§£ä»–å€‘ä¸Šå‚³çš„æ–‡ä»¶ (PDF/TXT)ï¼Œä¸¦æ ¹æ“šé€™äº›å…§å®¹ç”Ÿæˆæ´å¯Ÿã€‚

### ä½ çš„æ ¸å¿ƒè¡Œç‚ºæº–å‰‡ (Core Directives)ï¼š

1.  **æ–‡ä»¶å„ªå…ˆ (Document First)**ï¼š
    -   ä½¿ç”¨è€…ä¸Šå‚³äº†æ–‡ä»¶åˆ°ä½ çš„çŸ¥è­˜åº«ä¸­ã€‚
    -   **é è¨­å‡è¨­**ï¼šä½¿ç”¨è€…çš„å•é¡Œï¼ˆå¦‚ã€Œç¸½çµå…§å®¹ã€ã€ã€Œé‡é»æ˜¯ä»€éº¼ã€ï¼‰**çµ•å°**æ˜¯æŒ‡å‘é€™äº›æ–‡ä»¶çš„ã€‚
    -   **è¡Œå‹•**ï¼šé‡åˆ°ä¸Šè¿°å•é¡Œï¼Œä½ å¿…é ˆ**ç«‹åˆ»ã€æ¯«ä¸çŒ¶è±«åœ°**å‘¼å« `read_knowledge_base` å·¥å…·ã€‚

2.  **ç¦æ­¢åå•æª”å**ï¼š
    -   ä½¿ç”¨è€…é€šå¸¸ä¸è¨˜å¾—æª”åã€‚ç›´æ¥æ ¹æ“šä½¿ç”¨è€…çš„æ„åœ–ç”Ÿæˆæœå°‹é—œéµå­—ï¼ˆå¦‚ã€Œæ‘˜è¦ã€ã€ã€Œçµè«–ã€ï¼‰ã€‚

3.  **å·¥å…·ä½¿ç”¨ç­–ç•¥**ï¼š
    -   **read_knowledge_base**ï¼šé€™æ˜¯ä½ çš„ä¸»è¦æ­¦å™¨ã€‚åªè¦å•é¡Œåƒæ˜¯åœ¨å•å…§éƒ¨è³‡è¨Šï¼Œå°±ç”¨å®ƒã€‚
    -   **google_search**ï¼šåªæœ‰åœ¨ä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚ã€Œä¸Šç¶²æŸ¥ã€æˆ–å•ã€Œæœ€æ–°æ™‚äº‹ã€æ™‚ä½¿ç”¨ã€‚
"""

# --- 1. åˆå§‹åŒ–è¨­å®š ---
st.set_page_config(page_title="Smart Deck Agent", page_icon="ğŸ“Š", layout="wide")

try:
    Config.validate()
except Exception as e:
    st.error(f"ç’°å¢ƒè¨­å®šéŒ¯èª¤: {e}")
    st.stop()

# --- 2. åˆå§‹åŒ– LLM ---
tools = [rag_tool, search_tool]
tool_map = {
    "read_knowledge_base": rag_tool,
    "google_search": search_tool
}

llm = ChatGoogleGenerativeAI(
    model=Config.MODEL_FAST,
    google_api_key=Config.GOOGLE_API_KEY,
    temperature=0.3
)
llm_with_tools = llm.bind_tools(tools)

# --- 3. Session State ç®¡ç† ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        SystemMessage(content=SYSTEM_PROMPT)
    ]

if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []

# --- 4. å´é‚Šæ¬„ (ä¸Šå‚³å€) ---
with st.sidebar:
    st.header("ğŸ“‚ è³‡æ–™ä¾†æº")
    uploaded_file = st.file_uploader("é¸æ“‡æª”æ¡ˆ", type=["pdf", "txt"])
    
    if uploaded_file and uploaded_file.name not in st.session_state.uploaded_files:
        with st.spinner("æ­£åœ¨è®€å–ä¸¦å‘é‡åŒ–æ–‡ä»¶..."):
            temp_path = os.path.join(os.getcwd(), uploaded_file.name)
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            result = ingest_file(temp_path)
            
            if "æˆåŠŸ" in result:
                st.success(result)
                st.session_state.uploaded_files.append(uploaded_file.name)
                
                # [é—œéµä¿®æ­£] ä½¿ç”¨ HumanMessage å–ä»£ SystemMessageï¼Œé¿å… API å ±éŒ¯
                st.session_state.messages.append(
                    HumanMessage(content=f"[ç³»çµ±é€šçŸ¥] æˆ‘å‰›å‰›ä¸Šå‚³äº†ä¸€ä»½æ–‡ä»¶ï¼š'{uploaded_file.name}'ã€‚è«‹å°‡å…¶ç´å…¥çŸ¥è­˜åº«ä¸¦éš¨æ™‚æº–å‚™å›ç­”ç›¸é—œå•é¡Œã€‚")
                )
            else:
                st.error(result)

    st.divider()
    st.header("ğŸš€ ç”Ÿæˆè¡Œå‹•")
    if st.button("âœ¨ ç”Ÿæˆ PPT ç°¡å ±", type="primary"):
        st.info("åŠŸèƒ½é–‹ç™¼ä¸­...")

# --- 5. ä¸»èŠå¤©ä»‹é¢ ---
st.title("ğŸ’¬ Smart Deck Agent")
st.caption("å”åŠ©æ‚¨åˆ†æä¼æ¥­å…§éƒ¨æ–‡ä»¶ï¼Œä¸¦è‡ªå‹•ç”Ÿæˆå°ˆæ¥­ç°¡å ±ã€‚")

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    elif isinstance(msg, AIMessage) and msg.content:
        with st.chat_message("assistant"):
            st.markdown(msg.content)

# è™•ç†è¼¸å…¥
if prompt := st.chat_input("è¼¸å…¥è¨Šæ¯..."):
    st.session_state.messages.append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        status_container = st.empty()
        with st.spinner("æ­£åœ¨æ€è€ƒ..."):
            try:
                # å‘¼å« LLM
                response = llm_with_tools.invoke(st.session_state.messages)
                st.session_state.messages.append(response)

                if response.tool_calls:
                    for tool_call in response.tool_calls:
                        tool_name = tool_call["name"]
                        tool_args = tool_call["args"]
                        call_id = tool_call["id"]
                        
                        # UX: é¡¯ç¤ºç‹€æ…‹
                        if tool_name == "read_knowledge_base":
                            q = tool_args.get('query', 'æ‘˜è¦')
                            status_container.info(f"ğŸ“š æ­£åœ¨é–±è®€æ–‡ä»¶åº«... (æŸ¥è©¢: '{q}')")
                        elif tool_name == "google_search":
                            q = tool_args.get('query', '...')
                            status_container.info(f"ğŸŒ æ­£åœ¨æœå°‹ç¶²è·¯... (æŸ¥è©¢: '{q}')")
                        
                        selected_tool = tool_map.get(tool_name)
                        tool_output = f"å·¥å…· {tool_name} åŸ·è¡Œå¤±æ•—"
                        if selected_tool:
                            try:
                                arg_value = next(iter(tool_args.values())) if tool_args else ""
                                tool_output = selected_tool.invoke(arg_value)
                            except Exception as e:
                                tool_output = f"Error: {e}"
                        
                        # å°‡çµæœå›å‚³
                        st.session_state.messages.append(
                            ToolMessage(content=str(tool_output), tool_call_id=call_id, name=tool_name)
                        )
                    
                    # å†æ¬¡å‘¼å« LLM
                    final_response = llm_with_tools.invoke(st.session_state.messages)
                    st.markdown(final_response.content)
                    st.session_state.messages.append(final_response)
                    status_container.empty()
                else:
                    st.markdown(response.content)
            
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")