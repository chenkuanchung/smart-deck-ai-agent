# src/app.py
import streamlit as st
import os
import sys

# è·¯å¾‘ä¿®æ­£
current_file_path = os.path.abspath(__file__)
src_dir = os.path.dirname(current_file_path)
project_root = os.path.dirname(src_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Import
from src.config import Config
# [æ–°å¢ import] remove_file_from_db
from src.tools.rag import ingest_file, rag_tool, reset_vector_store, remove_file_from_db
from src.tools.search import search_tool
from src.graph import agent_workflow
from src.agents.state import AgentState
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage

# System Prompt
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€å€‹æ™ºæ…§å‹æ–‡ä»¶åˆ†æèˆ‡ç°¡å ±åŠ©æ‰‹ (Smart Deck Agent)ã€‚
1. **æ–‡ä»¶å„ªå…ˆ**ï¼šä½¿ç”¨è€…å•ç¸½çµæˆ–å…§å®¹æ™‚ï¼Œå„ªå…ˆæŸ¥ `read_knowledge_base`ã€‚
2. **å·¥å…·ç­–ç•¥**ï¼šéœ€è¦å¤–éƒ¨è³‡è¨Šæ‰æŸ¥ `Google Search`ã€‚
3. **ç¦æ­¢åå•**ï¼šä¸è¦å•ä½¿ç”¨è€…æª”åï¼Œç›´æ¥æœå°‹é—œéµå­—ã€‚
"""

# 1. Init
st.set_page_config(page_title="Smart Deck Agent", page_icon="ğŸ“Š", layout="wide")
try:
    Config.validate()
except Exception as e:
    st.error(f"ç’°å¢ƒè¨­å®šéŒ¯èª¤: {e}")
    st.stop()

# 2. LLM
tools = [rag_tool, search_tool]
tool_map = {"read_knowledge_base": rag_tool, "google_search": search_tool}
llm = ChatGoogleGenerativeAI(
    model=Config.MODEL_FAST,
    google_api_key=Config.GOOGLE_API_KEY,
    temperature=0.3
)
llm_with_tools = llm.bind_tools(tools)

# 3. Session State
if "messages" not in st.session_state:
    st.session_state.messages = [SystemMessage(content=SYSTEM_PROMPT)]

# ç”¨ä¾†è¿½è¹¤ã€Œç›®å‰è³‡æ–™åº«è£¡æœ‰å“ªäº›æª”æ¡ˆã€
if "db_files" not in st.session_state:
    st.session_state.db_files = set() 

# 4. å´é‚Šæ¬„ (æ™ºæ…§åŒæ­¥å€)
with st.sidebar:
    st.header("ğŸ“‚ è³‡æ–™ä¾†æº")
    
    # accept_multiple_files=True è®“æˆ‘å€‘å¯ä»¥ä¸€æ¬¡ç®¡ç†å¤šå€‹æª”æ¡ˆï¼Œä¹Ÿæ–¹ä¾¿åšåˆªé™¤åµæ¸¬
    uploaded_files = st.file_uploader(
        "é¸æ“‡æª”æ¡ˆ (PDF/TXT)", 
        type=["pdf", "txt"], 
        accept_multiple_files=True
    )
    
    # --- [æ ¸å¿ƒé‚è¼¯] è‡ªå‹•åŒæ­¥æ©Ÿåˆ¶ ---
    if uploaded_files is not None:
        # 1. å–å¾—ç›®å‰ UI ä¸Šçš„æª”æ¡ˆåç¨±æ¸…å–®
        current_ui_filenames = {f.name for f in uploaded_files}
        
        # 2. æ‰¾å‡ºã€Œæ–°ä¸Šå‚³ã€çš„ (UI æœ‰ï¼Œä½† DB æ²’è¨˜éŒ„)
        new_files = [f for f in uploaded_files if f.name not in st.session_state.db_files]
        
        # 3. æ‰¾å‡ºã€Œè¢«åˆªé™¤ã€çš„ (DB æœ‰è¨˜éŒ„ï¼Œä½† UI æ²’æœ‰äº†)
        removed_files = st.session_state.db_files - current_ui_filenames
        
        # è™•ç†æ–°æª”æ¡ˆ
        for file in new_files:
            with st.spinner(f"æ­£åœ¨è™•ç†æ–°æª”æ¡ˆï¼š{file.name}..."):
                temp_path = os.path.join(os.getcwd(), file.name)
                with open(temp_path, "wb") as f:
                    f.write(file.getbuffer())
                
                result = ingest_file(temp_path)
                if "æˆåŠŸ" in result:
                    st.success(result)
                    st.session_state.db_files.add(file.name)
                    st.session_state.messages.append(
                        HumanMessage(content=f"[ç³»çµ±é€šçŸ¥] æˆ‘ä¸Šå‚³äº† '{file.name}'ã€‚")
                    )
                else:
                    st.error(result)

        # è™•ç†è¢«åˆªé™¤çš„æª”æ¡ˆ
        for filename in removed_files:
            with st.spinner(f"æ­£åœ¨ç§»é™¤æª”æ¡ˆï¼š{filename}..."):
                msg = remove_file_from_db(filename)
                st.warning(msg)
                st.session_state.db_files.remove(filename)
                st.session_state.messages.append(
                    HumanMessage(content=f"[ç³»çµ±é€šçŸ¥] æˆ‘ç§»é™¤äº† '{filename}'ï¼Œè«‹ä¸è¦å†åƒè€ƒå®ƒçš„å…§å®¹ã€‚")
                )
    
    st.divider()
    
    # æ¸…ç©ºæŒ‰éˆ•
    if st.button("ğŸ—‘ï¸ Reset å…¨éƒ¨", type="secondary"):
        reset_vector_store()
        st.session_state.db_files = set()
        st.session_state.messages = [SystemMessage(content=SYSTEM_PROMPT)]
        st.rerun()

    st.header("ğŸš€ ç”Ÿæˆè¡Œå‹•")
    if st.button("âœ¨ ç”Ÿæˆ PPT ç°¡å ±", type="primary"):
        if not st.session_state.messages:
            st.warning("è«‹å…ˆå°è©±")
        else:
            with st.status("ğŸ¤– AI åœ˜éšŠå·¥ä½œä¸­...", expanded=True) as status:
                chat_history = ""
                for msg in st.session_state.messages:
                    if isinstance(msg, HumanMessage):
                        chat_history += f"User: {msg.content}\n"
                    elif isinstance(msg, AIMessage) and msg.content:
                        chat_history += f"AI: {msg.content}\n"
                
                status.write("ğŸ§  Manager è¦åŠƒå¤§ç¶±...")
                initial_state = {"user_request": "è£½ä½œç°¡å ±", "chat_history": chat_history}
                final_state = agent_workflow.invoke(initial_state)
                
                status.write("âœï¸ Writer æ’°å¯«èˆ‡æ’ç‰ˆ...")
                if final_state.get("final_file_path"):
                    ppt_path = final_state["final_file_path"]
                    file_name = os.path.basename(ppt_path)
                    with open(ppt_path, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è¼‰ PPT", f, file_name)
                    status.update(label="âœ… å®Œæˆï¼", state="complete")
                else:
                    status.error("ç”Ÿæˆå¤±æ•—")

# 5. ä¸»èŠå¤©å€
st.title("ğŸ’¬ Smart Deck Agent")

for msg in st.session_state.messages:
    if isinstance(msg, HumanMessage):
        with st.chat_message("user"):
            st.markdown(msg.content)
    elif isinstance(msg, AIMessage) and msg.content:
        with st.chat_message("assistant"):
            st.markdown(msg.content)

if prompt := st.chat_input("è¼¸å…¥è¨Šæ¯..."):
    st.session_state.messages.append(HumanMessage(content=prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        status_box = st.empty()
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                response = llm_with_tools.invoke(st.session_state.messages)
                st.session_state.messages.append(response)

                if response.tool_calls:
                    for tool_call in response.tool_calls:
                        name = tool_call["name"]
                        args = tool_call["args"]
                        call_id = tool_call["id"]
                        
                        if name == "read_knowledge_base":
                            status_box.info(f"ğŸ“š æŸ¥é–±è³‡æ–™åº«: {args.get('query')}")
                        elif name == "google_search":
                            status_box.info(f"ğŸŒ æœå°‹ç¶²è·¯: {args.get('query')}")
                        
                        tool = tool_map.get(name)
                        output = tool.invoke(next(iter(args.values())) if args else "") if tool else "Error"
                        
                        st.session_state.messages.append(
                            ToolMessage(content=str(output), tool_call_id=call_id, name=name)
                        )
                    
                    final_res = llm_with_tools.invoke(st.session_state.messages)
                    st.markdown(final_res.content)
                    st.session_state.messages.append(final_res)
                    status_box.empty()
                else:
                    st.markdown(response.content)
            except Exception as e:
                st.error(f"Error: {e}")