# src/tools/rag.py
import os
import shutil
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_core.tools import Tool
from src.config import Config

# è¨­å®šè·¯å¾‘
PERSIST_DIRECTORY = os.path.join(os.getcwd(), "chroma_db")

embeddings = GoogleGenerativeAIEmbeddings(
    model=Config.MODEL_EMBEDDING,
    google_api_key=Config.GOOGLE_API_KEY
)

vector_store = Chroma(
    collection_name="smart_deck_docs",
    embedding_function=embeddings,
    persist_directory=PERSIST_DIRECTORY
)

def ingest_file(file_path: str):
    """è®€å–æª”æ¡ˆä¸¦å­˜å…¥å‘é‡åº«"""
    file_path = os.path.abspath(file_path)
    if not os.path.exists(file_path): return f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {file_path}"
    
    try:
        if file_path.lower().endswith('.pdf'): loader = PyPDFLoader(file_path)
        elif file_path.lower().endswith('.txt'): loader = TextLoader(file_path, encoding='utf-8')
        else: return "âŒ åªæ”¯æ´ PDF/TXT"

        docs = loader.load()
        for doc in docs: doc.metadata["source"] = file_path
            
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
        
        if splits:
            vector_store.add_documents(documents=splits)
            return f"âœ… å·²å­˜å…¥çŸ¥è­˜åº«: {os.path.basename(file_path)}"
        return "âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©ºã€‚"
    except Exception as e:
        return f"âŒ è®€å–å¤±æ•—ï¼š{str(e)}"

def remove_file_from_db(filename: str):
    try:
        file_path = os.path.abspath(os.path.join(Config.UPLOAD_DIR, filename))
        existing_docs = vector_store.get(where={"source": file_path})
        if existing_docs['ids']:
            vector_store.delete(ids=existing_docs['ids'])
        
        if os.path.exists(file_path): os.remove(file_path)
        return f"ğŸ—‘ï¸ å·²ç§»é™¤ {filename}"
    except Exception as e: return f"âŒ ç§»é™¤å¤±æ•—ï¼š{e}"

def reset_vector_store():
    global vector_store
    try:
        try: vector_store.delete_collection()
        except: pass
        
        vector_store = Chroma(
            collection_name="smart_deck_docs",
            embedding_function=embeddings,
            persist_directory=PERSIST_DIRECTORY
        )
        
        if os.path.exists(Config.UPLOAD_DIR):
            shutil.rmtree(Config.UPLOAD_DIR)
            os.makedirs(Config.UPLOAD_DIR)
        return "âœ… é‡ç½®å®Œæˆ"
    except Exception as e: return f"âŒ é‡ç½®å¤±æ•—: {e}"

def query_knowledge_base(query: str):
    """
    æŸ¥è©¢çŸ¥è­˜åº«ã€‚
    [é—œéµå„ªåŒ–]ï¼šå¦‚æœçŸ¥è­˜åº«æ˜¯ç©ºçš„ï¼Œç›´æ¥å›å‚³ç‰¹å®šå­—ä¸²å¼•å° Agent å» Googleã€‚
    """
    try:
        # æª¢æŸ¥ Collection æ˜¯å¦æœ‰è³‡æ–™
        # ChromaDB çš„ get() é»˜èªå›å‚³æ‰€æœ‰ IDï¼Œå¦‚æœç‚ºç©º list ä»£è¡¨æ²’è³‡æ–™
        check_empty = vector_store.get()
        if not check_empty['ids']:
            return "ã€ç³»çµ±æç¤ºã€‘ï¼šç›®å‰çŸ¥è­˜åº«æ˜¯ç©ºçš„ï¼ˆä½¿ç”¨è€…å°šæœªä¸Šå‚³ä»»ä½•æ–‡ä»¶ï¼‰ã€‚è«‹ç«‹åˆ»æ”¹ç”¨ `Google Search` æŸ¥è©¢å¤–éƒ¨è³‡è¨Šã€‚"

        results = vector_store.similarity_search(query, k=4)
        if not results:
            return "çŸ¥è­˜åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚å»ºè­°ä½¿ç”¨ google_searchã€‚"
        return "\n\n".join([f"---ç‰‡æ®µ---\n{doc.page_content}" for doc in results])
    except Exception as e:
        return f"æœå°‹å¤±æ•—ï¼š{str(e)}"

rag_tool = Tool(
    name="read_knowledge_base",
    description="è®€å–å·²ä¸Šå‚³çš„æ–‡ä»¶ã€‚è‹¥ç„¡ä¸Šå‚³æ–‡ä»¶ï¼Œè«‹å‹¿ä½¿ç”¨æ­¤å·¥å…·ã€‚",
    func=query_knowledge_base
)