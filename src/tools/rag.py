# src/tools/rag.py
import os
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_core.tools import Tool
from src.config import Config
import shutil

# è¨­å®šè·¯å¾‘
PERSIST_DIRECTORY = os.path.join(os.getcwd(), "chroma_db")

# åˆå§‹åŒ– Embedding
embeddings = GoogleGenerativeAIEmbeddings(
    model=Config.MODEL_EMBEDDING,
    google_api_key=Config.GOOGLE_API_KEY
)

# åˆå§‹åŒ– Vector Store
vector_store = Chroma(
    collection_name="smart_deck_docs",
    embedding_function=embeddings,
    persist_directory=PERSIST_DIRECTORY
)

def ingest_file(file_path: str):
    """è®€å–æª”æ¡ˆä¸¦å­˜å…¥å‘é‡åº«"""
    if not os.path.exists(file_path):
        return f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}"
    
    try:
        if file_path.lower().endswith('.pdf'):
            loader = PyPDFLoader(file_path)
        elif file_path.lower().endswith('.txt'):
            loader = TextLoader(file_path, encoding='utf-8')
        else:
            return "âŒ ç›®å‰åªæ”¯æ´ PDF èˆ‡ TXT"

        docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
        
        if splits:
            vector_store.add_documents(documents=splits)
            return f"âœ… æˆåŠŸï¼šå·²å°‡ {os.path.basename(file_path)} å­˜å…¥çŸ¥è­˜åº«ã€‚"
        else:
            return "âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©ºã€‚"
            
    except Exception as e:
        return f"âŒ è®€å–å¤±æ•—ï¼š{str(e)}"

# [æ–°å¢åŠŸèƒ½] æ ¹æ“šæª”ååˆªé™¤è³‡æ–™
def remove_file_from_db(filename: str):
    """å¾å‘é‡è³‡æ–™åº«ä¸­ç§»é™¤æŒ‡å®šæª”æ¡ˆçš„æ‰€æœ‰ç‰‡æ®µ"""
    try:
        # ChromaDB å­˜çš„æ™‚å€™æœƒæŠŠ file_path å¯«åœ¨ metadata çš„ 'source' æ¬„ä½
        # æˆ‘å€‘è¦é‚„åŸå‡ºç•¶åˆå­˜çš„çµ•å°è·¯å¾‘æ‰èƒ½åˆªé™¤
        file_path = os.path.join(os.getcwd(), filename)
        
        # ä½¿ç”¨ where æ¢ä»¶åˆªé™¤
        vector_store.delete(where={"source": file_path})
        return f"ğŸ—‘ï¸ å·²å¾çŸ¥è­˜åº«ç§»é™¤ï¼š{filename}"
    except Exception as e:
        return f"âŒ ç§»é™¤å¤±æ•—ï¼š{str(e)}"

def reset_vector_store():
    """æ¸…ç©ºæ•´å€‹çŸ¥è­˜åº«"""
    global vector_store
    try:
        try:
            vector_store.delete_collection()
        except:
            pass
        if os.path.exists(PERSIST_DIRECTORY):
            shutil.rmtree(PERSIST_DIRECTORY)
        vector_store = Chroma(
            collection_name="smart_deck_docs",
            embedding_function=embeddings,
            persist_directory=PERSIST_DIRECTORY
        )
        return "âœ… çŸ¥è­˜åº«å·²æ¸…ç©ºã€‚"
    except Exception as e:
        return f"âŒ é‡ç½®å¤±æ•—: {str(e)}"

def query_knowledge_base(query: str):
    """æœå°‹"""
    try:
        results = vector_store.similarity_search(query, k=4)
        if not results:
            return "çŸ¥è­˜åº«ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚"
        return "\n\n".join([f"---ç‰‡æ®µ---\n{doc.page_content}" for doc in results])
    except Exception as e:
        return f"æœå°‹å¤±æ•—ï¼š{str(e)}"

# Tool å®šç¾©
rag_tool = Tool(
    name="read_knowledge_base",
    description="è®€å–å·²ä¸Šå‚³çš„æ–‡ä»¶ã€‚ç”¨æ–¼æŸ¥è©¢å…§éƒ¨è³‡æ–™ã€‚",
    func=query_knowledge_base
)